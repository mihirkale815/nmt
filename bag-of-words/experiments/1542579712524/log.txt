data:	data/de-en_save
mono_data:	data/de-en_save_mono
logF:	experiments/
refF:	nist08.tok.ref
epoch:	50
batch_size:	64
optim:	adam
cell:	lstm
attention:	luong_gate
learning_rate:	0.0003
max_grad_norm:	1
learning_rate_decay:	0.5
start_decay_at:	8
emb_size:	512
hidden_size:	512
dec_num_layers:	2
enc_num_layers:	3
res_layers:	1
bidirectional:	True
dropout:	0.15
max_time_step:	50
eval_interval:	5000
save_interval:	1000
metrics:	['bleu']
shared_vocab:	False
beam_size:	5
unk:	False
schedule:	True
resRNN:	False
selfatt:	False
attemb:	False
hops:	3
schesamp:	False
length_norm:	True
config:	fr_en.yaml
gpus:	[]
restore:	
seed:	1234
model:	seq2seq
mode:	train
module:	seq2seq
log:	
num_processes:	4
char:	False
pool_size:	0
scale:	1
max_split:	0
split_num:	0
pretrain:	
alpha:	0.0
offset:	0
use_cuda:	False
src_vocab_size:	18706
tgt_vocab_size:	12460

seq2seq(
  (encoder): rnn_encoder(
    (embedding): Embedding(18706, 512)
    (attention): luong_gate_attention(
      (linear_in): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): Dropout(p=0.22)
      )
      (feed): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): Sigmoid()
        (5): Dropout(p=0.22)
      )
      (remove): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): Sigmoid()
        (5): Dropout(p=0.22)
      )
      (linear_out): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): SELU()
        (5): Dropout(p=0.22)
      )
      (mem_gate): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): Sigmoid()
        (5): Dropout(p=0.22)
      )
      (feed_vec): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
      )
      (softmax): Softmax()
    )
    (rnn): LSTM(512, 512, num_layers=3, dropout=0.15, bidirectional=True)
  )
  (decoder): rnn_decoder(
    (embedding): Embedding(12460, 512)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.15)
      (layers): ModuleList(
        (0): LSTMCell(512, 512)
        (1): LSTMCell(512, 512)
      )
    )
    (linear): Linear(in_features=512, out_features=12460, bias=True)
    (attention): luong_gate_attention(
      (linear_in): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): Dropout(p=0.22)
      )
      (feed): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): Sigmoid()
        (5): Dropout(p=0.22)
      )
      (remove): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): Sigmoid()
        (5): Dropout(p=0.22)
      )
      (linear_out): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): SELU()
        (5): Dropout(p=0.22)
      )
      (mem_gate): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): Sigmoid()
        (5): Dropout(p=0.22)
      )
      (feed_vec): Sequential(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): SELU()
        (2): Dropout(p=0.22)
      )
      (softmax): Softmax()
    )
    (dropout): Dropout(p=0.15)
  )
  (log_softmax): LogSoftmax()
  (softmax): Softmax()
  (criterion): CrossEntropyLoss()
  (multi_label_loss): MultiLabelSoftMarginLoss()
)

total number of parameters: 51227820

