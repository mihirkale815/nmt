{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from vocab import Vocab, VocabEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAttention(nn.Module):\n",
    "    def __init__(self,encoder_dim,decoder_dim):\n",
    "        super(ConcatAttention, self).__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.linear = nn.Linear(self.encoder_dim+self.decoder_dim,self.decoder_dim)\n",
    "        self.W = nn.Linear(self.decoder_dim,1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, hidden,encoder_outputs):\n",
    "        batchsize,maxlen,encoderdim = encoder_outputs.size()\n",
    "        print(hidden.size())\n",
    "        hidden = hidden.expand(-1,maxlen,-1) #B,1,D => B,L,D\n",
    "        input = torch.cat([encoder_outputs,hidden],dim=2)\n",
    "        energy = self.relu(self.linear(input))\n",
    "        scores = self.W(energy).squeeze(-1) #B x L\n",
    "        scores = F.softmax(scores,dim=1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab,embed_size,context_size,hidden_size,n_layers,dropout,attention):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.vocab = vocab\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(len(self.vocab),self.embed_size)\n",
    "        self.context_size = context_size\n",
    "        self.rnn = nn.LSTM(input_size=self.embed_size+self.context_size,hidden_size=self.hidden_size,\n",
    "                               num_layers=self.n_layers, batch_first=True)\n",
    "        self.embed_dropout = nn.Dropout(p=self.dropout)\n",
    "        self.attention = attention\n",
    "        self.linear = nn.Linear(self.hidden_size+self.context_size,len(vocab))\n",
    "\n",
    "    def forward(self,input,hidden,encoder_inputs):\n",
    "        embedding = self.embed(input)\n",
    "        attn_scores = self.attention(hidden[0].permute(1,0,2), encoder_inputs).unsqueeze(1)  # bs x 1 x maxlen\n",
    "        context = attn_scores.bmm(encoder_inputs).squeeze(1)\n",
    "        input = torch.cat([embedding,context],dim=1)\n",
    "        output,hidden = self.rnn(input.unsqueeze(1),hidden)\n",
    "        output = torch.cat([output.squeeze(1),context],dim=1)\n",
    "        output = F.log_softmax(self.linear(output),dim=1)\n",
    "        return output,hidden,attn_scores.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "decoder_embed_size = 100\n",
    "decoder_hidden_size = 100\n",
    "decoder_context_size = 100\n",
    "vocab = pickle.load(open('data/vocab.bin', 'rb'))\n",
    "attention = ConcatAttention(100,100)\n",
    "embed = nn.Embedding(100,100)\n",
    "decoder = RNNDecoder(vocab.src,decoder_embed_size,\n",
    "                     decoder_context_size,decoder_hidden_size,1,0.0,attention)\n",
    "sentences = torch.LongTensor([[1,2,3,4],[4,5,6,7],[3,6,1,2]])\n",
    "embeddings = embed(sentences)\n",
    "encoder_outputs = embeddings\n",
    "hidden = embeddings[:,1,:]\n",
    "res = attention(hidden.unsqueeze(1),encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "output,hidden,attn_scores = decoder(sentences[:,1],[hidden.unsqueeze(0),hidden.unsqueeze(0)],encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "output,hidden,attn_scores = decoder(sentences[:,1],hidden,encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 100]), torch.Size([1, 3, 100]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].size(),hidden[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs, encoder_hidden = encoder(source,sourcelens)\n",
    "predicted_target = torch.zeros(target.size())\n",
    "batch_size,max_len = target.size()\n",
    "for idx in range(0,max_len):\n",
    "    outputs,hidden,attn_scores = decoder(inputs,hidden,encoder_outputs)\n",
    "    inputs = target[:,idx]\n",
    "    predicted_target[:,idx] = outputs\n",
    "    \n",
    "loss = criterion(predicted_target.view(batch_size*max_len,len(vocab.trgt))\n",
    "                 ,targets.view(batch_size*max_len))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 4, 5],\n",
       "        [6, 7, 3],\n",
       "        [6, 1, 2]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
